jobs:
  stream_output:
    working-directory: ${{ inputs.rundir }}
    ssh:
      remoteHost: ${{ inputs.resource.ip }}
    steps:
      - name: Stream Output
        run: |
          touch run.${PW_JOB_ID}.out
          tail -f run.${PW_JOB_ID}.out &
          tail_pid=$!
          # Wait for CANCEL_STREAMING
          while [ ! -f "CANCEL_STREAMING" ]; do
            sleep 5
          done
          rm -f CANCEL_STREAMING
          echo "$(date) CANCEL_STREAMING file detected!"
          kill ${tail_pid}
  preprocessing:
    working-directory: ${{ inputs.rundir }}
    ssh:
      remoteHost: ${{ inputs.resource.ip }}
    steps:
      - name: Create Script Template
        run: |
          set -x
          if [[ "${{ inputs.use_existing_script }}" == true ]]; then
            if [ ! -f "${{ inputs.script_path }}" ]; then
                echo "(date) ERROR: File ${{ inputs.script_path }} does not exist or is not a regular file." >&2
                exit 1
            fi
            cp ${{ inputs.script_path }} run-template.sh
          else
          # Do not remove this indentation
          cat <<'EOF' > run-template.sh
          ${{ inputs.script }}
          EOF
          fi
          cat run-template.sh
      - name: Create SLURM Headers
        if: ${{ inputs.slurm.is_disabled == false }}
        run: |
          # Need to evaluate the env variables here
          cat <<EOF > headers.sh
          #SBATCH --job-name=${PW_JOB_ID}
          #SBATCH --time=${{ inputs.slurm.time }}
          #SBATCH --chdir=${PWD}
          #SBATCH -o ${PWD}/run.${PW_JOB_ID}.out
          #SBATCH -e ${PWD}/run.${PW_JOB_ID}.out
          EOF

          # Partition
          if ! [ -z "${{ inputs.slurm.partition_default }}" ]; then
            echo "#SBATCH --partition=${{ inputs.slurm.partition_default }}" >> headers.sh
          elif ! [ -z "${{ inputs.slurm.partition_hpc4 }}" ]; then
            echo "#SBATCH --partition=${{ inputs.slurm.partition_hpc4 }}" >> headers.sh
          fi

          # GPUs
          if ! [ -z "${{ inputs.slurm.gres_gpu_default }}" ]; then
            echo "#SBATCH --gres=gpu:${{ inputs.slurm.gres_gpu_default }}" >> headers.sh
          elif ! [ -z "${{ inputs.slurm.gres_gpu_hpc4 }}" ]; then
            echo "#SBATCH --gres=gpu:${{ inputs.slurm.gres_gpu_hpc4 }}" >> headers.sh
          fi

          # The scheduler directives parameter is always optional
          if ! [ -z "${{ inputs.slurm.scheduler_directives }}" ]; then
            echo "${{ inputs.slurm.scheduler_directives }}" >> headers.sh
          fi

          if [[ ${{ inputs.resource.provider }} == 'existing' ]]; then
            echo "#SBATCH --mem=${{ inputs.slurm.mem }}" >> headers.sh
            echo "#SBATCH --cpus-per-task=${{ inputs.slurm.cpus_per_task }}" >> headers.sh
          fi

          if ! [ -z "${{ inputs.slurm.slurm_options }}" ]; then
            echo "#SBATCH --clusters=${{ inputs.slurm.slurm_options }}" >> headers.sh
            echo "SLURM_OPTIONS_ARG=-M ${{ inputs.slurm.slurm_options }}" | tee -a $OUTPUTS
          else
            echo "SLURM_OPTIONS_ARG=" | tee -a $OUTPUTS
          fi

          echo "HEADERS=$(cat headers.sh)" | tee -a $OUTPUTS
          echo "SCHEDULER_TYPE=slurm" | tee -a $OUTPUTS

      - name: Create PBS Headers
        if: ${{ inputs.pbs.is_disabled == false }}
        run: |
          set -x
          cat <<EOF > headers.sh
          #PBS -N ${PW_JOB_ID}
          #PBS -o ${PWD}/run.${PW_JOB_ID}.out
          #PBS -j oe
          EOF

          # The scheduler directives parameter is always optional
          if ! [ -z "${{ inputs.pbs.scheduler_directives }}" ]; then
            echo "${{ inputs.pbs.scheduler_directives }}" >> headers.sh
          fi

          echo "HEADERS=$(cat headers.sh)" | tee -a $OUTPUTS
          echo "SCHEDULER_TYPE=pbs" | tee -a $OUTPUTS

  ssh_job:
    needs:
      - preprocessing
    if: ${{ inputs.slurm.is_disabled != false && inputs.pbs.is_disabled != false && inputs.use_scheduler_agent != true }}
    working-directory: ${{ inputs.rundir }}
    ssh:
      remoteHost: ${{ inputs.resource.ip }}
    steps:
      - name: Create Script
        run: |
          set -x
          cat <<EOF > run.sh
          ${{ inputs.shebang }}
          cd ${PWD}
          EOF
          cat run-template.sh >> run.sh
          chmod +x run.sh
          cat run.sh
      - name: Submit Script
        run: |
          set -x
          echo "$(date) Executing script"
          ./run.sh > run.${PW_JOB_ID}.out 2>&1
  pbs_job:
    needs:
      - preprocessing
    if: ${{ inputs.pbs.is_disabled == false && inputs.use_scheduler_agent != true }}
    working-directory: ${{ inputs.rundir }}
    ssh:
      remoteHost: ${{ inputs.resource.ip }}
    steps:
      - name: Create PBS Script
        run: |
          set -x
          echo "$(date) Creating PBS script"
          echo '${{ inputs.shebang }}' > run.sh
          cat headers.sh >> run.sh
          echo "cd ${PWD}" >> run.sh
          cat run-template.sh >> run.sh
          chmod +x run.sh
          cat run.sh
      - name: Submit PBS Script
        run: |
          set -x
          echo "$(date) Submitting PBS Job"
          jobid=$(qsub run.sh)
          jobid=$(echo "$jobid" | cut -d'.' -f1)
          if ! [[ "${jobid}" =~ ^[0-9]+$ ]]; then
            echo "$(date) Job submission failed: invalid jobid '${jobid}'"
            exit 1
          fi
          echo "jobid=${jobid}"  | tee -a $OUTPUTS
        cleanup: qdel "${{ needs.pbs_job.outputs.jobid }}"
      - name: Monitor PBS Job
        run: |
          jobid=${{ needs.pbs_job.outputs.jobid }}
          echo "$(date) Monitoring PBS job ${jobid}"
          get_pbs_job_status() {
            # Get the header line to determine the column index corresponding to the job status
            if [ -z "${QSTAT_HEADER}" ]; then
              export QSTAT_HEADER="$(qstat | awk 'NR==1')"
            fi
            status_response=$(qstat 2>/dev/null | grep "\<${jobid}\>")
            echo "${QSTAT_HEADER}"
            echo "${status_response}"
            export job_status="$(qstat -f ${jobid} 2>/dev/null  | grep job_state | cut -d'=' -f2 | tr -d ' ')"
          }
          while true; do
            sleep 15
            get_pbs_job_status
            if [[ "${job_status}" == "C" ]]; then
              break
            elif [ -z "${job_status}" ]; then
              break
            fi
          done
  slurm_job:
    needs:
      - preprocessing
    if: ${{ inputs.slurm.is_disabled == false && inputs.use_scheduler_agent != true }}
    working-directory: ${{ inputs.rundir }}
    ssh:
      remoteHost: ${{ inputs.resource.ip }}
    steps:
      - name: Create SLURM Script
        run: |
          set -x
          echo '${{ inputs.shebang }}' > run.sh
          cat headers.sh >> run.sh
          cat run-template.sh >> run.sh
          chmod +x run.sh
          cat run.sh
      - name: Submit SLURM Script
        run: |
          set -x
          echo "$(date) Submitting SLURM Job"
          jobid=$(sbatch run.sh | tail -1 | awk -F ' ' '{print $4}')
          if ! [[ "${jobid}" =~ ^[0-9]+$ ]]; then
            echo "$(date) Job submission failed: invalid jobid '${jobid}'"
            exit 1
          fi
          echo "jobid=${jobid}"  | tee -a $OUTPUTS
        cleanup: scancel ${{ needs.preprocessing.outputs.SLURM_OPTIONS_ARG }} ${{ needs.slurm_job.outputs.jobid }}
      - name: Monitor SLURM Job
        run: |
          jobid=${{ needs.slurm_job.outputs.jobid }}
          echo "$(date) Monitoring SLURM job ${jobid}"

          get_slurm_job_status() {
              # Get the header line to determine the column index corresponding to the job status
              if [ -z "${SQUEUE_HEADER}" ]; then
                  export SQUEUE_HEADER="$(eval squeue ${{ needs.preprocessing.outputs.SLURM_OPTIONS_ARG }} | awk 'NR==1')"
              fi
              status_column=$(echo "${SQUEUE_HEADER}" | awk '{ for (i=1; i<=NF; i++) if ($i ~ /^S/) { print i; exit } }')
              status_response=$(eval squeue ${{ needs.preprocessing.outputs.SLURM_OPTIONS_ARG }} | awk -v jobid="${jobid}" '$1 == jobid')
              echo "${SQUEUE_HEADER}"
              echo "${status_response}"
              export job_status=$(echo ${status_response} | awk -v id="${jobid}" -v col="$status_column" '{print $col}')
          }

          while true; do
            sleep 15
            get_slurm_job_status
            if [ -z "${job_status}" ]; then
              job_status=$(sacct -j ${jobid}  --format=state | tail -n1)
              echo "$(date) Job exited with status ${job_status}"
              break
            fi
          done
  scheduler_agent_job:
    needs:
      - preprocessing
    if: ${{ inputs.use_scheduler_agent == true }}
    working-directory: ${{ inputs.rundir }}
    ssh:
      remoteHost: ${{ inputs.resource.ip }}
    steps:
      - name: Create Script
        run: |
          set -x
          echo '${{ inputs.shebang }}' > run.sh
          cat run-template.sh >> run.sh
          chmod +x run.sh
          cat run.sh
      - uses: parallelworks/scheduler-agent
        id: slurmstep
        with:
          scheduler-type: ${{ needs.preprocessing.outputs.SCHEDULER_TYPE }}
          script-headers: |
            ${{ needs.preprocessing.outputs.HEADERS }}
          wait: false
      - uses: parallelworks/wait-for-agent
        id: waitstep
        with:
          agentId: ${{ needs.scheduler_agent_job.steps.slurmstep.outputs.agentId }}
      - name: Run Script
        ssh:
          jumpNodeHost: ${{ inputs.resource.ip }}
          remoteHost: ${{ needs.scheduler_agent_job.steps.waitstep.outputs.remoteHost }}:${{ needs.scheduler_agent_job.steps.waitstep.outputs.sshPort }}
        run: |
          set -x
          echo "$(date) Executing script"
          ./run.sh > run.${PW_JOB_ID}.out 2>&1


  cleanup:
    if: ${{ always }}
    needs:
      - ssh_job
      - pbs_job
      - slurm_job
      - scheduler_agent_job
    working-directory: ${{ inputs.rundir }}
    ssh:
      remoteHost: ${{ inputs.resource.ip }}
    steps:
      - name: Cleanup
        run: |
          set -x
          touch COMPLETED
        cleanup: |
          set -x
          touch CANCEL_STREAMING
          if [ -f COMPLETED ]; then
            rm -f COMPLETED
            echo "$(date) job was completed "
            exit 0
          fi 

'on':
  execute:
    inputs:
      resource:
        label: Resource Target
        type: compute-clusters
        autoselect: true
        optional: false
      shebang:
        label: Shebang
        type: string
        default: '#!/bin/bash'
      rundir:
        label: Run Directory
        type: string
        default: ${PWD}
        tooltip: The directory in which the script will be executed. Defaults to the job’s current working directory ($PWD).
      use_existing_script:
        type: boolean
        default: false
        label: Use Existing Script?
        tooltip: |
          Yes → Provide path to an existing script on the target resource.
          No  → Type the script
      script:
        label: Type Script
        type: editor
        hidden: ${{ inputs.use_existing_script == true }}
        ignore: ${{ .hidden }}
        tooltip: Type the script to run without shebang and scheduler directives.
        default: |
          echo "$(date) Running in directory ${PWD} on ${HOSTNAME}"
      script_path:
        label: Script Path
        type: string
        hidden: ${{ inputs.use_existing_script == false }}
        ignore: ${{ .hidden }}
        tooltip: Provide path to an existing script on the target resource.
      scheduler:
        type: boolean
        default: false
        label: Schedule Job?
        hidden: ${{ inputs.resource.schedulerType == '' }}
        ignore: ${{ .hidden }}
        tooltip: |
          Yes → Job is submitted to the scheduler using sbatch, qsub, etc
          No  → Job is executed in the controller or login node instead
      use_scheduler_agent:
        type: boolean
        ignore: ${{ inputs.scheduler == false }}
        hidden: ${{ .ignore }}
        default: false
        label: Use parallelworks/scheduler-agent?
        tooltip: |
          Yes → Provision the compute node using parallelworks/scheduler-agent
          No  → Directly use sbatch, qsub, etc to submit the job
      slurm:
        type: group
        label: SLURM Directives
        hidden: ${{ inputs.resource.provider == 'existing' && inputs.resource.schedulerType != 'slurm' || inputs.scheduler == false }}
        ignore: ${{ inputs.resource.provider == 'existing' && inputs.resource.schedulerType != 'slurm' || inputs.scheduler == false }}
        items:
          slurm_options:
            type: dropdown
            label: Select Cluster
            optional: true
            default: ''
            options:
              - value: ''
                label: Default
              - value: 'hpc4'
                label: HPC4
          is_disabled:
            type: boolean
            hidden: true
            default: ${{ inputs.resource.provider == 'existing' && inputs.resource.schedulerType != 'slurm' || inputs.scheduler == false }}
            label: Is SLURM disabled?
          partition_default:
            type: slurm-partitions
            label: SLURM partition
            ignore: ${{ 'hpc4' == inputs.slurm.slurm_options }}
            hidden: ${{ .ignore }}
            optional: true
            resource: ${{ inputs.resource }}
            tooltip: Select a partition from the drop down menu. Leave empty to let SLURM pick a partition.
          partition_hpc4:
            type: dropdown
            label: SLURM partition
            optional: true
            tooltip: Select a partition from the drop down menu. Leave empty to let SLURM pick a partition.
            ignore: ${{ 'hpc4' != inputs.slurm.slurm_options }}
            hidden: ${{ .ignore }}
            default: normal
            options:
              - normal
              - gpu
              - gpu-h200
              - gpu-quick
              - ht
              - large-mem
              - quick
              - test
              - unlimited
          cpus_per_task:
            type: number
            label: CPUs per task
            min: 1
            max: 32
            default: 1
            tooltip: '--cpus-per-task=value slurm directive'
            ignore: ${{ 'existing' != inputs.resource.provider }}
            hidden: ${{ .ignore }}
          mem:
            type: string
            label: Minimum total memory required
            default: 8GB
            tooltip: '--mem=value slurm directive'
            hidden: ${{ 'existing' != inputs.resource.provider }}
            ignore: ${{ .hidden }}
            optional: true
          gres_gpu_default:
            type: number
            label: Number of GPUs
            ignore: ${{ ( inputs.slurm.partition_default != 'gpu' && inputs.slurm.partition_default != 'gpu-quick' ) || 'existing' != inputs.resource.provider  }}
            hidden: ${{ .ignore }}
            min: 1
            max: 4
            default: 1
            tooltip: '--gres=gpu:X slurm directive'
          gres_gpu_hpc4:
            type: number
            label: Number of GPUs
            hidden: ${{ ( inputs.slurm.partition_hpc4 != 'gpu' && inputs.slurm.partition_hpc4 != 'gpu-quick' && inputs.slurm.partition_hpc4 != 'gpu-h200' ) || 'existing' != inputs.resource.provider  }}
            ignore: ${{ .hidden }}
            optional: ${{ .hidden }}
            min: 1
            max: 4
            default: 1
            tooltip: '--gres=gpu:X slurm directive'
          time:
            label: Walltime
            type: string
            default: '01:00:00'
            tooltip: '--time= SLURM directive to set the maximum wall-clock time limit for the job'
          scheduler_directives:
            type: editor
            optional: true
            tooltip: |
              Type in additional scheduler directives. 
      pbs:
        type: group
        label: PBS Directives
        hidden: ${{ inputs.resource.schedulerType != 'pbs' || inputs.scheduler == false }}
        ignore: ${{ inputs.resource.schedulerType != 'pbs' || inputs.scheduler == false }}
        items:
          is_disabled:
            type: boolean
            hidden: true
            default: ${{ inputs.resource.schedulerType != 'pbs' || inputs.scheduler == false }}
            label: Is PBS disabled?
          scheduler_directives:
            label: Scheduler Directives
            type: editor
            tooltip: Type the PBS scheduler directives
            ignore: ${{ inputs.resource.schedulerType != 'pbs' || inputs.scheduler == false }}