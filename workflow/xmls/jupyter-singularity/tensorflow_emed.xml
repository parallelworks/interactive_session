<tool id='User.Demo_jupyter_docker_tensorflow_cloud' name='User.Demo_jupyter_docker_tensorflow_cloud'>
  <command interpreter='bash'>main.sh</command>
  <cancel interpreter='bash'>kill.sh</cancel>
  <inputs>
    <param 
      name='advanced_options_stream' 
      label='Stream slurm output?' 
      type='hidden' 
      value='false'
    ></param>
    <section name='service' type='section' title='Jupyter Server' expanded='true'>
      <param 
        name='name' 
        label='Service' 
        type='hidden' 
        value='jupyter-singularity'
      ></param>
      <param 
        name='password' 
        label='Password for notebook session' 
        type='hidden' 
        value='' 
        help='Enter password or leave blank for no password'
      ></param>
      <param 
        name='path_to_sing' 
        label='Path to singularity container' 
        type='text' 
        value='/public/apps/singularity/containers/tensorflow_latest-gpu-jupyter-extra.sif' 
        help='Path to the singularity container in the execution host'
      ></param>
      <param 
        name="use_gpus" 
        type="boolean" 
        truevalue="Yes" 
        falsevalue="No"
        checked="True" 
        value="true"
        label="Use GPUs?" 
        help='Select Yes to run a CUDA application inside a container'
      ></param>
    </section>
    <section name='pwrl_host' type='section' title='Service host' expanded='true'>
      <param 
        name='resource' 
        type='computeResource'
        label='Service host' 
        hideUserWorkspace='true' 
        help='Resource to host the service'
        hideDisconnectedResources='false'
      ></param>
      <param 
        name='nports' 
        label='Number of Ports to Reserve' 
        type='hidden' 
        value='1'  
      ></param> 
      <param 
        name='jobschedulertype' 
        label='Select Controller, SLURM Partition or PBS Queue' 
        type='hidden' 
        value='SLURM'
      ></param>
      <param 
        name='_sch__dd_partition_e_' 
        label='SLURM partition' 
        type='text' 
        help='Partition to submit the interactive job. Leave empty to let SLURM pick the optimal option.' 
        optional='true'  
      ></param>
      <param 
        name='_sch__dd_cpus_d_per_d_task_e_' 
        label='CPUs per task' 
        type='integer' 
        min="1" 
        max="10" 
        help='--cpus-per-task=value slurm directive' 
        value='1'
      ></param>
      <param 
        name='_sch__dd_mem_e_' 
        label='Minimum total memory required' 
        type='text' 
        help='--mem=value slurm directive' 
        value='8G'
        optional='true'  
      ></param>   
      <param 
        name='_sch__dd_time_e_' 
        label='Walltime' 
        type='text' 
        help='e.g. 01:00:00 - Amount of time slurm will honor the interactive session.' 
        value='01:00:00'
        optional='true'  
      ></param>
      <param 
        name='scheduler_directives' 
        label='Scheduler directives' 
        type='text' 
        help='e.g. --mem=1000;--gpus-per-node=1 - Use the semicolon character ; to separate parameters. Do not include the SBATCH keyword.' 
        optional='true'  
      ></param>
    </section>
  </inputs>
  <outputs>
  </outputs>
</tool>
