permissions:
  - '*'
sessions:
  session:
    redirect: true

jobs:
  preprocessing:
      ssh:
        remoteHost: ${{ inputs.cluster.resource.ip }}
      steps:
        - name: Checkout
          uses: parallelworks/checkout
          with:
            repo: https://github.com/parallelworks/interactive_session.git
            branch: main
            sparse_checkout:
              - ${{ inputs.service.name }}
        - name: Create Inputs
          run: |
            set -x
            # Write PW variables
            env | grep '^PW_' | grep -v 'PW_API_KEY' > inputs.sh
            # Encase values between quotes
            sed -i 's/=\(.*\)/="\1"/' inputs.sh
            # Write input form variables and ensure the pw agent is in the PATH
            cat <<'EOF' >> inputs.sh
            PATH=$HOME/pw:$PATH
            service_novnc_parent_install_dir="${{ inputs.service.novnc_parent_install_dir }}"
            service_novnc_tgz_basename="${{ inputs.service.novnc_tgz_basename }}"
            juice_use_juice="${{ inputs.juice.use_juice }}"
            juice_pool_ids="${{ inputs.juice.pool_ids }}"
            juice_vram="${{ inputs.juice.vram }}"
            juice_cmd_args="${{ inputs.juice.cmd_args }}"
            EOF
            if ! [ -z "${{ org.JUICE_TOKEN }}" ]; then
              echo "JUICE_TOKEN=${{ org.JUICE_TOKEN }}" >> inputs.sh
            fi
            # Remove empty variables
            sed -i '/=\s*$\|=undefined\s*$/d' inputs.sh
            sed -i '/=""/d' inputs.sh # remove var=""
            # Add export= to all lines
            sed -i 's/^/export /' inputs.sh

  session_runner:
    needs:
      - preprocessing
    ssh:
        remoteHost: ${{ inputs.cluster.resource.ip }}
    steps:
      - uses: marketplace/session_runner/v1.3
        early-cancel: any-job-failed
        with:
          session: ${{ sessions.session }}
          resource: ${{ inputs.cluster.resource }}
          cluster:
            scheduler: ${{ inputs.cluster.scheduler }}
            slurm:
              is_disabled: ${{ inputs.cluster.resource.provider == 'existing' && inputs.cluster.resource.schedulerType != 'slurm' || inputs.cluster.scheduler == false  }}
              partition: ${{ inputs.cluster.slurm.partition }}
              scheduler_directives: ${{ inputs.cluster.slurm.scheduler_directives }}
              time: ${{ inputs.cluster.slurm.time }}
            pbs:
              is_disabled: ${{ inputs.cluster.resource.schedulerType != 'pbs' || inputs.cluster.scheduler == false }}
              scheduler_directives: ${{ inputs.cluster.pbs.scheduler_directives }}
          service:
            start_service_script: ${PW_PARENT_JOB_DIR}/${{ inputs.service.name }}/start-template-v3.sh
            controller_script: ${PW_PARENT_JOB_DIR}/${{ inputs.service.name }}/controller-v3.sh
            inputs_sh: ${PW_PARENT_JOB_DIR}/inputs.sh
            rundir: ${PW_PARENT_JOB_DIR}


'on':
  execute:
    inputs:
      targetType:
        label: Target Type
        type: dropdown
        default: compute-cluster
        options:
          - label: Compute Cluster
            value: compute-cluster
          - label: Kubernetes Cluster
            value: kubernetes-cluster
      cluster:
        type: group
        label: Compute Cluster Settings
        items:
          resource:
            type: compute-clusters
            label: Service host
            include-workspace: false
            tooltip: Resource to host the service
          scheduler:
            type: boolean
            default: false
            label: Schedule Job?
            hidden: ${{ inputs.cluster.resource.schedulerType == '' }}
            ignore: ${{ .hidden }}
            tooltip: |
              Yes → Job is submitted to the scheduler using sbatch, qsub, etc
              No  → Job is executed in the controller or login node instead
          slurm:
            type: group
            label: SLURM Directives
            hidden: ${{ inputs.cluster.resource.provider == 'existing' && inputs.cluster.resource.schedulerType != 'slurm' || inputs.cluster.scheduler == false  }}
            items:
              is_disabled:
                type: boolean
                hidden: true
                default: ${{ inputs.cluster.resource.provider == 'existing' && inputs.cluster.resource.schedulerType != 'slurm' || inputs.cluster.scheduler == false }}
                label: Is SLURM disabled?
              partition:
                type: slurm-partitions
                label: SLURM partition
                ignore: ${{ inputs.cluster.resource.provider == 'existing' && inputs.cluster.resource.schedulerType != 'slurm' || inputs.cluster.scheduler == false }}
                optional: true
                resource: ${{ inputs.cluster.resource }}
                tooltip: Select a partition from the drop down menu.
              time:
                label: Walltime
                type: string
                default: '01:00:00'
                ignore: ${{ inputs.cluster.resource.provider == 'existing' && inputs.cluster.resource.schedulerType != 'slurm' || inputs.cluster.scheduler == false }}
                tooltip: '--time= SLURM directive to set the maximum wall-clock time limit for the job'
              scheduler_directives:
                type: editor
                ignore: ${{ inputs.cluster.resource.provider == 'existing' && inputs.cluster.resource.schedulerType != 'slurm' || inputs.cluster.scheduler == false }}
                optional: true
                tooltip: |
                  Type in additional scheduler directives. 
          pbs:
            type: group
            label: PBS Directives
            hidden: ${{ inputs.cluster.resource.schedulerType != 'pbs' || inputs.cluster.scheduler == false }}
            items:
              is_disabled:
                type: boolean
                hidden: true
                default: ${{ inputs.cluster.resource.schedulerType != 'pbs' || inputs.cluster.scheduler == false }}
                label: Is PBS disabled?
              scheduler_directives:
                label: Scheduler Directives
                type: editor
                tooltip: Type the PBS scheduler directives
                hidden: ${{ inputs.cluster.resource.schedulerType != 'pbs' || inputs.cluster.scheduler == false }}
      service:
        type: group
        hidden: true
        label: Webshell
        items:
          name:
            type: string
            hidden: true
            default: webshell
          novnc_parent_install_dir:
            label: noVNC installation directory
            type: string
            hidden: true
            default: ${HOME}/pw/software
          novnc_tgz_basename:
            label: Basename of the novnc tgz file
            type: string
            hidden: true
            default: noVNC-1.3.0.tgz
      juice:
        type: group
        label: Attached GPU Settings
        collapsed: true
        hidden: ${{ org.JUICE_TOKEN == "" }}
        items:
          use_juice:
            label: Enable Juice?
            type: boolean
            default: false
            tooltip: Enable Juice to access and share remote GPUs over a network for your workload.
          pool_ids:
            label: Pool IDs
            type: string
            hidden: ${{ inputs.juice.use_juice == false }}
            ignore: ${{ .hidden }}
            optional: true
            tooltip: Comma separated list of pool ids from which to allocate the session resources, when empty any available pool you have access to is used
          vram:
            label: VRAM
            type: string
            hidden: ${{ inputs.juice.use_juice == false }}
            ignore: ${{ .hidden }}
            optional: true
            tooltip: Amount of VRAM requested in gibibytes. Can return a session with fewer bytes if there is not enough space on the device. Suffixes can be provided for convenience. E.g. 4 GiB (default "0")
          cmd_args:
            label: Juice Run Command Arguments
            type: string
            hidden: ${{ inputs.juice.use_juice == false }}
            ignore: ${{ .hidden }}
            optional: true
            tooltip: Optional arguments for the juice run command to customize workload execution, e.g., "--gpu-ids string".
